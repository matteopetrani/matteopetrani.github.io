---
layout: post
title: "NÂ°003 - Interface me"
date: 2025-02-07 07:24:01 +0000
author: "Matteo Petrani"
original: 2025-02-07-interfacciami.md
telegram: ""
excerpt: "Interfacing with AI means going beyond prompts and defending awareness, ethics and humanity in our conversations with the machine."
---

This week I started working with BlackPep and Intarget again as Head of CRO. I have been collaborating with them for 8 months now to increase the conversion of e-commerce, mainly in the luxury & fashion sectors. A separate post would be needed to tell everything I'm learning.

The companies that dominate the S&P 500 have seen some truly folkloric CEOs in their history. Just to name a few: Ballmer (Microsoft), used to entering the stage as if he were at Tomorrowland; Bezos and Musk, who flex the largest "space dicks"; Zuck, who has the superpower of turning carrot-colored.

On the other hand, there are the boys next door: Sundar Pichai, Sam Altman and, him, Jensen Huang.

Necessary disclaimer: I have never gone on an MTB raid with them, nor a coffee, nor do they answer me on Telegram. I speak a little by osmosis.

Jensen, with his balanced manner and with great mental presence, in an interview that I recommend you watch, comes out bluntly: we must learn to interface with AI. Not him, us. We followers, we who have learned to say yes with great emphasis to every innovation.

## Is it just prompting?

If you haven't added "prompt engineering" to your skills on LinkedIn yet, I'm sorry: it's useless to run now to do it. The algorithm does not reward the last.

It is also true that, without good priming and prompting, the answers begin to converge a lot: the wider the perimeter of the question, the more the various models will give average answers, which tend to resemble each other.

If we then go beyond simple operational requests and start asking for opinions on our own business, without a bit of awareness of these technologies, the answers often seem human, sometimes even rich in emotions.

The question arises spontaneously: after how many messages do we begin to lose the awareness of talking to a machine? Spoiler: few. And they have known this since 1966, when the ELIZA program was born to test how easily one risks anthropomorphizing a computer.

Jaron Lanier always knows a lot and warns us: we risk "dissolving" human authenticity in algorithms that replicate and redistribute content. True, on the one hand this empowers us; on the other, we should ask ourselves if we are actually interacting or passively undergoing the answers of a system.

## "Hello, I'm a man"

People are people. No? Of course, they are! It wasn't a trick question. Think about how we communicate with each other. What a wonderful mess we are not? Our communication is a dance of emotions, intuitions, unsaids, silences and nuances. We dialogue with our eyes, with our hands, with our hearts at times! Every word is an island of meaning in the sea of â€‹â€‹a shared cultural context.

With AI, we are in the pond of a datacenter. We give an input and we get an output. There is no soul, there is no mystery, there is no life. It is an interaction that looks more like a surgical operation than a chat at the bar. And we, convinced of our superiority, believe we are clever in managing this game.

## A very sweet deception

The danger is anthropomorphization. That little voice in our head that makes us believe that AI is a kind of "artificial friend". We begin to project expectations on it that it can never satisfy. We consider it wise, empathetic, almost human. And so, we find ourselves blindly trusting its answers, more than those of our grandmother.

The truth, however, is that AI is neither good nor bad, neither wise nor foolish. It is a machine, and as such it must be used.

Learning to interface with AI means not only becoming a little more savvy with prompts, but above all knowing how to navigate these technological waves. The literacy of the future will not be knowing how to write prompts, but knowing how to discern what is true from what is false, what is authentic from what is simulated.

To do this, we need a recipe made of critical awareness, ethical sense and humanity. Knowing the limits and biases of AI to balance its answers, using it with responsibility (how boring, right?) and always asserting our ingenuity and imagination.

Federico Faggin, who has seen two transistors in his life, says: "Machines will never be conscious, because they are devoid of the self-awareness and creativity that comes from human experience". And he's damn right.

## Let's play ðŸ¦‘

The statistics speak for themselves: Gartner says that 75% of companies will use AI by 2025. Statista tells us that 42% of workers fear for their jobs. Gartner estimates that 85% of AI outputs are affected by bias. And we, in the midst of this storm, must understand how to navigate without being overwhelmed.

Do you realize what a wonderfully crazy period we are living in? What an incredible opportunity we have to assert our humanity?

As a professional, it is a moment to navigate with full sails to guide companies, train people, design for man and give voice to the ethics that we feel born from the heart.

As a person, I live all this by looking inside myself, trying to bring out the most human thing there is in my thoughts and actions.

At the end of the day, I believe that interfacing with AI is a way of interfacing with ourselves.

Cool links

 - [Living in the Savannah](https://www.youtube.com/watch?v=igI9QKW0bQ8): one of the most beautiful videos of Project Happiness

I'll leave you only one because it's worth it and I don't want to take up more than 1 hour of your screentime.
