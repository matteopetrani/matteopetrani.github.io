---
layout: post
title: "NÂ°010 - I am always right"
date: 2025-04-20 06:18:01 +0000
author: "Matteo Petrani"
original: 2025-04-20-ho-sempre-ragione.md
telegram: ""
excerpt: "Entrusting emotions and conflicts to AI makes us less human: let's go back to slow conversations, to doubt and to offline spaces where we can hold the helm by hand."
---

This week we're back to talking about AI; many questions arise when I look at Noah and think about his future.

For our mental health, fortunately the metaverse was a huge piece of crap and has been forgotten by most. On the other hand, I suspect that AI will remain.

For some time I have been wondering, as a good sailor perhaps a little in advance, about the type of principles I would like to pass on to Noah, especially in relation to technology and in relation to the stochastic parrots also called ChatGPT, Gemini, Grok, Claude and the others.

Do these apparently perfect travel companions really risk becoming our Her? Probably not for those who, as adults, have developed a certain critical sense. On the other hand, a child or teenager runs the risk of finding it more reassuring to talk to an AI than to a classmate. In fact, an AI can act as a psychologist, a sparring partner and a pen pal in a perfect way. You can vomit everything on it and it will always be patient, always available, it will never say "boh" or "what the fuck are you saying?!". It doesn't get tired of reading you, it doesn't ghost you with the double blue check and now it has an even more human voice (have you heard that ChatGPT takes a breath between one sentence and another? WTF!).

Aren't we raising a generation of cabin boys who prefer the reassuring monotony of the emotional autopilot to the uncertain thrill of holding the helm in the waves of human relationships?

## Priming and system prompt

If you try to ask for feedback on your behavior, a doubt, a disturbance that you take to bed with you at night, you will always receive an apparently perfect answer. Each LLM has its own personality, from the Christian Democrat LLama, to the more swaggering Grok and the gray ChatGPT. Details scripted in the system prompt that substantially describe how and in what tone to talk to us. The only way to get us to respond with firmness and humanity is to do the proper priming, that is, a partial override of the system prompt. For example "You are a psychologist who doesn't mince words, with a Buddhist inclination but also a bit of an asshole and funny". On second thought, however, we are designing our interlocutor, giving him a shape that we like. I don't know if it's the best way, it requires effort and commitment and by default it reinforces our bubble. To compete with the desire to grow, we have to deal with an AI that pampers us emotionally. Who can ever win in the long run? In an attempt to make AI more "human", we have made the comparison with true humanity, the one made of bad days, misunderstandings and clumsiness, an almost... defective experience. The algorithm becomes the benchmark, and we, poor hulls full of emotional leaks and improvised repairs, are the ones who are not up to par.

## Sailing by sight?

Here the matter becomes philosophical. We are getting used to being less and less tolerant of human complexity (boring, which requires time, true listening, and maybe even some discussion). Furthermore, the risk is that even human interactions become like interfaces: input, output, expected result. If it doesn't arrive, it's a bug in the "human" system with the risk of atrophy of our ability to navigate complex emotions. Of building bonds that require vulnerability, repairs and the acceptance that you don't always immediately understand where the other is going.

We are losing the ability to navigate by feeling, to read the stars of empathy, because we rely on an emotional GPS that always gives us the most "efficient" route. But efficient does not necessarily mean "rich" or "true".

## Let's get our hands (and hearts) dirty again

So, what do we do? Do we throw all the technology overboard? Of course not. I challenge you to manage your home banking, open the restaurant menu in PDF or send a photo of your nephew to your grandmother with a Light Phone III. But maybe we need to relearn how to choose when to rely on the autopilot and when to hold the helm steady, even if the sea is rough.

 1. Welcome back, Emotional Swell: Let's make sure that uncertainty, "I don't know", "let's talk about it better" are part of the journey. The clarity gained with difficulty is worth more than that served without request.
 2. A Less Perfect AI: higher and higher scores on the tests are welcome, but let it show some cracks, admit that it "doesn't know", that maybe every now and then it "loses its compass". Imperfection is a gift.
 3. As in the cockpit: We create sacred offline spaces. Like in the cockpit of a boat, the most romantic and human place to create moments where you can talk without filters, without fear of being clumsy or slow. There you really learn to be with what is there.
 4. That healthy distrust: let's distrust answers that are too easy. Let's learn to ask ourselves: who programmed this "compass"? What doesn't it see? Where can't it go? The shortcut is not always the best way.
 5. Four Chats Below Deck: Let's find time for real conversations, even the uncomfortable ones, the ones that maybe end in a "we didn't understand each other". It is there that you see the stuff of the sailor, not in the perennial calm.

The final irony would be to discover that, in an attempt to create perfect travel companions, we have made ourselves less interesting, less able to face the unpredictability of the real ocean. Are we perhaps trading the ability to navigate for real with the comfortable illusion of a cruise without waves?

What course are you holding?

Good wind (and keep an eye on your inner compass).

What I'm reading

 - Thinking, Fast and Slow
